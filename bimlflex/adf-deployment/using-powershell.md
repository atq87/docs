---
uid: adf-using-powershell
title: Deployment Through PowerShell
---
# Deployment Through PowerShell

For a walk-through of creating a BimlFlex solution that targets ADF, review the [Synapse ADF Implementation Guide](../implementation-guides/synapse-implementation-introduction.md).

You have generated your Azure Data Factory (ADF) assets, and are ready to deploy. This document will discuss deployment using ARM templates by using powershell. For information on how to deploy using the Azure Portal, review our [Azure Portal Deployment  Guide](using-azure-portal.md).

## Prerequisites

You need to ensure that you have your **arm_template.json** and **arm_template_parameters.json** files in your project's output folder. The path will look like this: 
` ...\output\DataFactories\<Setting.AzureDataFactoryName>\arm_template.json`

> [!NOTE]
> If there is no value specified, **BimlFlex** will be used for the folder name.  It is important to note that the actual ADF Data Factory Name will be a something similar to `ADF-<RandomHashValue>`.  It is recommended that you populate the configure your `Settings` and configure the **AzureDataFactoryName** setting prior to building your ADF.

## ARM Template Parameters File

An ARM template can include parameters that allow the user to customize the deployment. For example, a user can provide values that are tailored for a specific environment (eg. dev, test, or production). In PowerShell, the user can specify these parameters as arguments to the command, or they can include them in a parameter file and pass in that file. In BimlFlex, we generate that file for you, populated with specific values that are taken directly from your project settings.

|Parameter Name|BimlFlex Setting|Description|
|-|-|-|
|AzureFunctionBridgeName_functionKey.value|AzureFunctionBridgeKey|
|BimlFlexAutogeneratedKeyVaultSettings.keyVaultName| AzureKeyVault|
|BimlFlexAzureFunctionBridgeSettings.value.AppInsightsName| AzureFunctionBridgeName| [VALUE]-AI |
|BimlFlexAzureFunctionBridgeSettings.value.AppName| AzureFunctionBridgeName| 
|BimlFlexAzureFunctionBridgeSettings.value.FunctionKey| AzureFunctionBridgeKey| 
|BimlFlexAzureFunctionBridgeSettings.value.StorageAccountName| AzureFunctionBridgeName| [VALUE]sa |
|BimlFlexAzureFunctionBridgeSettings.value.WebFarmName| AzureFunctionBridgeName| [VALUE]-WF |
|factoryName.value| AzureDataFactoryName


**Example: SQL ADF arm_template_parameters.json**
```json
{
  "$schema": "https://schema.management.azure.com/schemas/2015-01-01/deploymentParameters.json#",
  "contentVersion": "1.0.0.0",
  "parameters": {
    "BimlFlexAutogeneratedKeyVaultSettings": {
      "value": {
        "keyVaultName": "AKV-281a7eeb2eb3d",
        "skuName": "Standard"
      }
    },
    "factoryName": {
      "value": "ADF-281a7eeb2eb3d"
    }
  }
}
```
>[!IMPORTANT]
>The `factoryName` property above is randomly generated if the `AzureDataFactoryName` setting is not populated. Using the generated GUID is poor practice. It does not represent anything visually, and can lead to mistakes. If the user did not populate this setting, but still wishes to use one single Data Factory in development and deployment, simply copy this value into the settings file now.

>[!IMPORTANT]
>The `BimlFlexAutogeneratedKeyVaultSettings.keyVaultName` property above is randomly generated if the `AzureKeyVault` setting is not populated. Using the generated GUID is poor practice. It does not represent anything, visually, and the GUID is generated upon each build, meaning that there is the potential to accidentally create a high number of KeyVaults.

**Example: SnowFlake ADF arm_template_parameters.json**
```json
{
  "$schema": "https://schema.management.azure.com/schemas/2015-01-01/deploymentParameters.json#",
  "contentVersion": "1.0.0.0",
  "parameters": {
    "AzureFunctionBridgeName_functionKey": {
      "value": "AzureFunctionBridgeKey"
    },
    "BimlFlexAutogeneratedKeyVaultSettings": {
      "value": {
        "keyVaultName": "AzureKeyVault",
        "skuName": "Standard"
      }
    },
    "BimlFlexAzureFunctionBridgeSettings": {
      "value": {
        "AppInsightsName": "AzureFunctionBridgeName-AI",
        "AppName": "AzureFunctionBridgeName",
        "DeployAppInsights": true,
        "FunctionKey": "AzureFunctionBridgeKey",
        "StorageAccountName": "azurefunctionbridgenamesa",
        "StorageAccountType": "Standard_LRS",
        "WebFarmName": "AzureFunctionBridgeName-WF"
      }
    },
    "factoryName": {
      "value": "AzureDataFactoryName"
    }
  }
}
```
## Generated SSDT Deployment Files
Note each time you build your solution, BimlFlex will also create a deployment file(s) titled `ssdt-deploy.[ASSET_NAME].ps1`, where `ASSET_NAME` corresponds to a data store. This is the case whether it is for staging, persistant staging, data vault, or data mart. Any time that you make changes to the schema of these assets, these deployment files need to be run, otherwise your project may fail to build. These scripts are located at `...\output\Deploy\` in the solution file structure.    

## Generated Deployment File

Once you have run any `ssdt-deploy.ps1` with outstanding schema changes, you are ready to deploy your ADF assets. BimlFlex generates an easy to use PowerShell script that enables you to simply run it and deploy your ADF assets. The script can be found at `...\output\Deploy\` and the file name should match the following pattern: <br>
 `adf-deploy.<Setting.AzureDataFactoryName>.ps1`.
>[!NOTE] 
>Execution only requires running the *.ps1 file and not manually running the PowerShell commands. 

>[!IMPORTANT]
>If there is no value specified for the AzureDataFactoryName setting the actual ADF Data Factory Name will be a something similar to `ADF-<RandomHashValue>`. 

The file contents show the commands that are used. At the top of the file are some commented-out commands that are needed to both install the cmdlets and connect to the specified environment. 

```powershell
# If required run the following command to install the Azure cmdlets 
# Install-Module -Name Az -AllowClobber -Scope CurrentUser
â€‹
# If required run the following command to connect to your Azure account             
# Connect-AzAccount  
```
> [!NOTE]
>If further details on the generated commands are needed, or to create these commands manually, refer the the article linked below.
> 
> Microsoft Docs:
> [Get started with Azure PowerShell](https://docs.microsoft.com/en-us/powershell/azure/get-started-azureps)  
> [Connect-AzAccount](https://docs.microsoft.com/en-us/powershell/module/az.accounts/connect-azaccount)  

Now, similar to the arm_template_parameters file above, BimlFlex generates variables that store setting values from the project, and passes them into the deployment commands.

```powershell
# Provide your Subscription and ResourceGroupName below 
$azureSubscriptionId = "00000000-0000-0000-0000-000000"
$azureResourceGroup = "BFX_Test"

$outputBasePath = "C:\Varigence-Test\ADF-ELT-SQLDW\output\";
$armTemplatePath = "$($outputBasePath)\DataFactories\BimlFlex\arm_template.json"
$armTemplateParamsPath = "$($outputBasePath)\DataFactories\BimlFlex\arm_template_parameters.json"
```

|Parameter Name|BimlFlex Setting|Description|
|-|-|-|
|$azureSubscriptionId|AzureSubscriptionId| 
|$azureResourceGroup| AzureResourceGroup|
|$outputBasePath| OutputPath| This is the BimlFlex project's output path. |
|$armTemplatePath| AzureDataFactoryName| If not supplied then `BimlFlex` is used.|
|$armTemplateParamsPath| AzureDataFactoryName| If not supplied then `BimlFlex` is used.|

Once this file is run, the deployment of the ADF assets using the generated powershell should now be successful.  

## Post Deployment

Pipeline(s) are now available for verification or running inside the ADF [Authoring Tool](https://docs.microsoft.com/en-us/azure/data-factory/author-visually). Pipelines can either be run manually or are run off of triggers. BimlFlex does not generate triggers by default, leaving the user with two options.

1. Create the Triggers themselves and deploy them to the Data Factory, either in the [Authoring Tool](https://docs.microsoft.com/en-us/azure/data-factory/author-visually) or via PowerShell.

2. Users can take advantage of BimlFlex [Extension Points](../reference-documentation/extension-point-definitions.md) and create them for each batch. An example extension point that creates an ADF trigger is listed below. This trigger will now be created inside of the ARM template file and deployed with the rest of the ADF assets.

```Biml
<#@ extension bundle="BimlFlex.bimlb" extensionpoint="AdfTrigger" #>
<#@ property name="batch" type="BimlFlexModelWrapper.BatchesWrapper" #>
<Schedule Name="ScheduleTriggerName" Frequency="Hour" Interval="1" Start="2001-01-01" End="2020-12-31">
        <Pipelines>
            <Pipeline PipelineName="0_<#=batch.Name #>_Batch">
                <Parameters>
                    <Parameter Name="IsInitialLoad">false</Parameter>
                </Parameters>
            </Pipeline>
        </Pipelines>
    </Schedule>
```
>[!NOTE]
>This will create a trigger that will run the pipeline, once every hour from January 1st, 2001, to December 31st, 2020.

Once a trigger is deployed, it must be started. Either manually using the [Authoring Tool](https://docs.microsoft.com/en-us/azure/data-factory/author-visually) or by running the following command in PowerShell:

```powershell
Start-AzDataFactoryV2Trigger -ResourceGroupName $ResourceGroupName -DataFactoryName $DataFactoryName -Name "ScheduleTriggerName"
``` 